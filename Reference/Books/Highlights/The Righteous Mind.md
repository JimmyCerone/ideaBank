# The Righteous Mind: Why Good People Are Divided by Politics and Religion

* Author: [[Jonathan Haidt]]
* ASIN: [[B0052FF7YM]]
* Reference: https://www.amazon.com/dp/B0052FF7YM
* [Kindle link](kindle://book?action=open&asin=B0052FF7YM)


  - > By the end of the tour, I hope to have given you a new way to think about two of the most important, vexing, and divisive topics in human life: politics and religion. (location: 62)


  - > But I chose the title The Righteous Mind to convey the sense that human nature is not just intrinsically moral, it’s also intrinsically moralistic, critical, and judgmental. (location: 72)


  - > I want to show you that an obsession with righteousness (leading inevitably to self-righteousness) is the normal human condition. It is a feature of our evolutionary design, not a bug or error that crept into minds that would otherwise be objective and rational.6 (location: 83)


  - > I yearn for a world in which competing ideologies are kept in balance, systems of accountability keep us all from getting away with too much, and fewer people believe that righteous ends justify violent means. Not a very romantic wish, but one that we might actually achieve. (location: 89)


  - > Moral intuitions arise automatically and almost instantaneously, long before moral reasoning has a chance to get started, and those first intuitions tend to drive our later reasoning. (location: 94)
    Fascinating. Same conclusion as Kendi?

  - > But if you think about moral reasoning as a skill we humans evolved to further our social agendas—to justify our own actions and to defend the teams we belong to—then things will make a lot more sense. (location: 97)


  - > They’re mostly post hoc constructions made up on the fly, crafted to advance one or more strategic objectives. (location: 99)


  - > The rider is our conscious reasoning—the stream of words and images of which we are fully aware. The elephant is the other 99 percent of mental processes—the ones that occur outside of awareness but that actually govern most of our behavior.8 I developed this metaphor in my last book, The Happiness Hypothesis, where I described how the rider and elephant work together, sometimes poorly, as we stumble through life in search of meaning and connection. (location: 101)


  - > which is that there’s more to morality than harm and fairness. The central metaphor of these four chapters is that the righteous mind is like a tongue with six taste receptors. Secular Western moralities are like cuisines that try to activate just one or two of these receptors—either concerns about harm and suffering, or concerns about fairness and injustice. (location: 108)


  - > why politicians on the right have a built-in advantage when it comes to cooking meals that voters like. (location: 113)


  - > Morality binds and blinds. (location: 114)


  - > human beings are 90 percent chimp and 10 percent bee. (location: 115)


  - > We are indeed selfish hypocrites so skilled at putting on a show of virtue that we fool even ourselves. (location: 117)


  - > People bind themselves into political teams that share moral narratives. Once they accept a particular narrative, they become blind to alternative moral worlds. (location: 128)
    Ie me.

  - > It is the realization that we are all self-righteous hypocrites: Why do you see the speck in your neighbor’s eye, but do not notice the log in your own eye?… You hypocrite, first take the log out of your own eye, and then you will see clearly to take the speck out of your neighbor’s eye. (MATTHEW 7:3–5) (location: 136)


  - > Understanding the simple fact that morality differs around the world, and even within societies, is the first step toward understanding your righteous mind. (location: 180)


  - > “Is moral thinking any different from other kinds of thinking?” I said that thinking about moral issues (such as whether abortion is wrong) seemed different from thinking about other kinds of questions (such as where to go to dinner tonight), because of the much greater need to provide reasons justifying your moral judgments to other people. (location: 189)


  - > In other words, the understanding of the conservation of volume wasn’t innate, and it wasn’t learned from adults. Kids figure it out for themselves, but only when their minds are ready and they are given the right kinds of experiences. (location: 215)


  - > It is, rather, self-constructed as kids play with other kids. Taking turns in a game is like pouring water back and forth between glasses. No matter how often you do it with three-year-olds, they’re just not ready to get the concept of fairness,7 any more than they can understand the conservation of volume. (location: 223)
    Wow. So do your kids friends have a big impact on them?

  - > Young children judged right and wrong by very superficial features, such as whether a person was punished for an action. (If an adult punished the act, then the act must have been wrong.) (location: 240)


  - > Kids at this stage generally care a lot about conformity, and they have great respect for authority—in word, if not always in deed. They rarely question the legitimacy of authority, even as they learn to maneuver within and around the constraints that adults impose on them. (location: 246)


  - >  (location: 254)
    So why are so many adults bad at this?

  - > Kohlberg’s most influential finding was that the most morally advanced kids (according to his scoring technique) were those who had frequent opportunities for role taking—for putting themselves into another person’s shoes and looking at a problem from that person’s perspective. Egalitarian relationships (such as with peers) invite role taking, but hierarchical relationships (such as with teachers and parents) do not. (location: 259)


  - >  (location: 267)
    Wow. That’s ground breaking.

  - > But by using a framework that predefined morality as justice while denigrating authority, hierarchy, and tradition, it was inevitable that the research would support worldviews that were secular, questioning, and egalitarian. (location: 271)
    Interesting...

  - > Children construct their moral understanding on the bedrock of the absolute moral truth that harm is wrong. Specific rules may vary across cultures, but in all of the cultures Turiel examined, children still made a distinction between moral rules and conventional rules.14 (location: 293)


  - > It’s about harm and fairness (not loyalty, respect, duty, piety, patriotism, or tradition). Hierarchy and authority are generally bad things (so it’s best to let kids figure things out for themselves). Schools and families should therefore embody progressive principles of equality and autonomy (not authoritarian principles that enable elders to train and constrain children). (location: 297)


  - >  (location: 323)
    Girard at it again.

  - > There must be more to moral development than kids constructing rules as they take the perspectives of other people and feel their pain. There must be something beyond rationalism. (location: 352)


  - > The individualistic answer largely vanquished the sociocentric approach in the twentieth century as individual rights expanded rapidly, consumer culture spread, and the Western world reacted with horror to the evils perpetrated by the ultrasociocentric fascist and communist empires. (European nations with strong social safety nets are not sociocentric on this definition. They just do a very good job of protecting individuals from the vicissitudes of life.) (location: 370)


  - > In other words, Shweder found almost no trace of social conventional thinking in the sociocentric culture of Orissa, where, as he put it, “the social order is a moral order.” Morality was much broader and thicker in Orissa; almost any practice could be loaded up with moral force. And if that was true, then Turiel’s theory became less plausible. Children were not figuring out morality for themselves, based on the bedrock certainty that harm is bad. (location: 390)


  - > Even in the United States the social order is a moral order, but it’s an individualistic order built up around the protection of individuals and their freedom. (location: 412)


  - > When you put individuals first, before society, then any rule or social practice that limits personal freedom can be questioned. If it doesn’t protect somebody from harm, then it can’t be morally justified. It’s just a social convention. (location: 415)


  - > Turiel’s rationalism predicted that reasoning about harm is the basis of moral judgment, so even though people might say it’s wrong to eat your dog, they would have to treat the act as a violation of a social convention. (We don’t eat our dogs, but hey, if people in another country want to eat their ex-pets rather than bury them, who are we to criticize?) Shweder’s theory, on the other hand, said that Turiel’s predictions should hold among members of individualistic secular societies but not elsewhere. I now had a study designed. I just had to find the elsewhere. (location: 443)


  - > First, all four of my Philadelphia groups confirmed Turiel’s finding that Americans make a big distinction between moral and conventional violations. I (location: 476)


  - > the size of the moral-conventional distinction varied across cultural groups. (location: 482)


  - >  (location: 486)
    Why?

  - > This was very strong support for Shweder’s claim that the moral domain goes far beyond harm. Most of my subjects said that the harmless-taboo violations were universally wrong even though they harmed nobody. (location: 493)


  - > Moral reasoning is usually done to influence other people (see chapter 4), and what the father is trying to do is get his curious son to feel the right emotions—disgust and fear—to motivate appropriate bathroom behavior. (location: 518)


  - > Was this an example of the “informational assumptions” that Turiel had talked about? Were people really condemning the actions because they foresaw these harms, or was it the reverse process—were people inventing these harms because they had already condemned the actions? (location: 525)


  - > They seemed to be morally dumbfounded—rendered speechless by their inability to explain verbally what they knew intuitively.29 These subjects were reasoning. They were working quite hard at reasoning. But it was not reasoning in search of truth; it was reasoning in support of their emotional reactions. (location: 538)


  - > We’re born to be righteous, but we have to learn what, exactly, people like us should be righteous about. (location: 567)


  - > One of the greatest truths in psychology is that the mind is divided into parts that sometimes conflict.1 To be human is to feel pulled in different directions, and to marvel—sometimes in horror—at your inability to control your own actions. (location: 569)


  - > This second soul contained those dreadful but necessary disturbances: pleasure, first of all, evil’s most powerful lure; then pains, that make us run away from what is good; besides these, boldness also and fear, foolish counselors both; then also the spirit of anger hard to assuage, and expectation easily led astray. These they fused with unreasoning sense perception and all-venturing lust, and so, as was necessary, they constructed the mortal type of soul.3 (location: 582)


  - > at least until you realize that this philosopher’s myth makes philosophers look pretty darn good. It justifies their perpetual employment as the high priests of reason, or as dispassionate philosopher-kings. It’s the ultimate rationalist fantasy—the passions are and ought only to be the servants of reason, to reverse Hume’s formulation. (location: 589)


  - > Western philosophy has been worshipping reason and distrusting the passions for thousands of years.4 There’s a direct line running from Plato through Immanuel Kant to Lawrence Kohlberg. (location: 594)


  - > I call it a delusion because when a group of people make something sacred, the members of the cult lose the ability to think clearly about it. Morality binds and blinds. (location: 596)


  - > After taking round after round of abuse rather passively, the heart finally rises to defend itself, and to put the head in its proper place—which is to handle problems that don’t involve people: (location: 614)


  - > Radical reformers usually want to believe that human nature is a blank slate on which any utopian vision can be sketched. If evolution gave men and women different sets of desires and skills, for example, that would be an obstacle to achieving gender equality in many professions. If nativism could be used to justify existing power structures, then nativism must be wrong. (Again, this is a logical error, but this is the way righteous minds work.) (location: 642)


  - > Do people believe in human rights because such rights actually exist, like mathematical truths, sitting on a cosmic shelf next to the Pythagorean theorem just waiting to be discovered by Platonic reasoners? Or do people feel revulsion and sympathy when they read accounts of torture, and then invent a story about universal rights to help justify their feelings? (location: 657)


  - > They retained full knowledge of what was right and wrong, and they showed no deficits in IQ. They even scored well on Kohlberg’s tests of moral reasoning. Yet when it came to making decisions in their personal lives and at work, they made foolish decisions or no decisions at all. They alienated their families and their employers, and their lives fell apart. Damasio’s interpretation was that gut feelings and bodily reactions were necessary to think rationally, and that one job of the vmPFC was to integrate those gut feelings into a person’s conscious deliberations. (location: 683)


  - > Just imagine what your life would be like if at every moment, in every social situation, picking the right thing to do or say became like picking the best washing machine among ten options, minute after minute, day after day. You’d make foolish decisions too. (location: 692)


  - > Yet the result of the separation was not the liberation of reason from the thrall of the passions. It was the shocking revelation that reasoning requires the passions. Jefferson’s model fits better: when one co-emperor is knocked out and the other tries to rule the empire by himself, he’s not up to the task. (location: 697)


  - > The head can’t even do head stuff without the heart. So Hume’s model fit these cases best: when the master (passions) drops dead, the servant (reasoning) has neither the ability nor the desire to keep the estate running. Everything goes to ruin. (location: 701)


  - > It pitted concerns about harm and life against concerns about law and property rights, and the story was well constructed to elicit cool, rational moral reasoning. Sure enough, (location: 736)


  - > Reasoning was merely the servant of the passions, and when the servant failed to find any good arguments, the master did not change his mind. (location: 799)


  - > Patterns, Thinking, and Cognition, by Howard Margolis, a professor of public policy at the University of Chicago. Margolis was trying to understand why people’s beliefs about political issues are often so poorly connected to objective facts, and he hoped that cognitive science could solve the puzzle. Yet Margolis was turned off by the approaches to thinking that were prevalent in the 1980s, most of which used the metaphor of the mind as a computer. (location: 808)


  - > Findings such as these led Wason to the conclusion that judgment and justification are separate processes. (location: 829)


  - > But the rationales (on this argument) are only ex post rationalizations. (location: 832)


  - > “Seeing-that” is the pattern matching that brains have been doing for hundreds of millions of years. Even the simplest animals are wired to respond to certain patterns of input (such as light, or sugar) with specific behaviors (such as turning away from the light, or stopping and eating the sugary food). Animals easily learn new patterns and connect them up to their existing behaviors, which can be reconfigured into new patterns as well (as when an animal trainer teaches an elephant a new trick). (location: 835)


  - > You can’t choose whether or not to see the illusion; you’re just “seeing-that” one line is longer than the other. Margolis also called this kind of thinking “intuitive.” (location: 842)


  - > “Reasoning-why,” in contrast, is the process “by which we describe how we think we reached a judgment, or how we think another person could reach that judgment.”34 “Reasoning-why” can occur only for creatures that have language and a need to explain themselves to other creatures. “Reasoning-why” is not automatic; it’s conscious, it sometimes feels like work, and it’s easily disrupted by cognitive load. Kohlberg had convinced moral psychologists to study “reasoning-why” and to neglect “seeing-that.”35 (location: 844)


  - > We do moral reasoning not to reconstruct the actual reasons why we ourselves came to a judgment; we reason to find the best possible reasons why somebody else ought to join us in our judgment.36 (location: 861)


  - > Emotions were long thought to be dumb and visceral, but beginning in the 1980s, scientists increasingly recognized that emotions were filled with cognition. Emotions occur in steps, the first of which is to appraise something that just happened based on whether it advanced or hindered your goals.38 (location: 869)


  - > Emotions are a kind of information processing.39 (location: 876)


  - > The crucial distinction is really between two different kinds of cognition: intuition and reasoning. (location: 879)


  - > Intuition is the best word to describe the dozens or hundreds of rapid, effortless moral judgments and decisions that we all make every day. Only a few of these intuitions come to us embedded in full-blown emotions. (location: 884)


  - > The rider can do several useful things. It can see further into the future (because we can examine alternative scenarios in our heads) and therefore it can help the elephant make better decisions in the present. It can learn new skills and master new technologies, which can be deployed to help the elephant reach its goals and sidestep disasters. (location: 892)


  - > The rider is skilled at fabricating post hoc explanations for whatever the elephant has just done, and it is good at finding reasons to justify whatever the elephant wants to do next. (location: 896)


  - > We make our first judgments rapidly, and we are dreadful at seeking out evidence that might disconfirm those initial judgments.43 Yet friends can do for us what we cannot do for ourselves: they can challenge us, giving us reasons and arguments (link 3) that sometimes trigger new intuitions, thereby making it possible for us to change our minds. We occasionally do this when mulling a problem by ourselves, suddenly seeing things in a new light or from a new perspective (to use two visual metaphors). (location: 913)


  - > Many of us believe that we follow an inner moral compass, but the history of social psychology richly demonstrates that other people exert a powerful force, able to make cruelty seem acceptable45 and altruism seem embarrassing,46 without giving us any reasons or arguments. (location: 922)


  - > The social intuitionist model offers an explanation of why moral and political arguments are so frustrating: because moral reasons are the tail wagged by the intuitive dog. A dog’s tail wags to communicate. You can’t make a dog happy by forcibly wagging its tail. And you can’t change people’s minds by utterly refuting their arguments. (location: 931)


  - >  (location: 936)
    Wish I’d known this 10 years ago...

  - > If you want to change people’s minds, you’ve got to talk to their elephants. You’ve got to use links 3 and 4 of the social intuitionist model to elicit new intuitions, not new rationales. (location: 937)


  - > Carnegie repeatedly urged readers to avoid direct confrontations. Instead he advised people to “begin in a friendly way,” to “smile,” to “be a good listener,” and to “never say ‘you’re wrong.’ ” The persuader’s goal should be to convey respect, warmth, and an openness to dialogue before stating one’s own case. (location: 940)


  - > “If there is any one secret of success it lies in the ability to get the other person’s point of view and see things from their angle as well as your own.”50 (location: 946)


  - >  (location: 949)
    Me...

  - > If you really want to change someone’s mind on a moral or political matter, you’ll need to see things from that person’s angle as well as your own. And if you do truly see it the other person’s way—deeply and intuitively—you might even find your own mind opening in response. Empathy is an antidote to righteousness, although it’s very difficult to empathize across a moral divide. (location: 951)


  - > You’ll misunderstand moral reasoning if you think about it as something people do by themselves in order to figure out the truth. (location: 964)


  - > Therefore, if you want to change someone’s mind about a moral or political issue, talk to the elephant first. If you ask people to believe something that violates their intuitions, they will devote their efforts to finding an escape hatch—a reason to doubt your argument or conclusion. They will almost always succeed. (location: 965)


  - > The first principle is Intuitions come first, strategic reasoning second. That’s a six-word summary of the social intuitionist model.2 (location: 985)


  - > I disliked being criticized, and I had felt a flash of negativity by the time Jayne had gotten to her third word (“Can you not …”). Even before I knew why she was criticizing me, I knew I disagreed with her (because intuitions come first). The instant I knew the content of the criticism (“… leave dirty dishes on the …”), my inner lawyer went to work searching for an excuse (strategic reasoning second). It’s true that I had eaten breakfast, given Max his first bottle, and let Andy out for his first walk, but these events had all happened at separate times. Only when my wife criticized me did I merge them into a composite image of a harried father with too few hands, and I created this fabrication by the time she had completed her one-sentence criticism (“… counter where I make baby food?”). I then lied so quickly and convincingly that my wife and I both believed me. (location: 1010)


  - > I finally understood—not just cerebrally but intuitively and with an open heart—the admonitions of sages from so many eras and cultures warning us about self-righteousness. (location: 1018)


  - > Animal brains make such appraisals thousands of times a day with no need for conscious reasoning, all in order to optimize the brain’s answer to the fundamental question of animal life: Approach or avoid? (location: 1030)


  - > Affect refers to small flashes of positive or negative feeling that prepare us to approach or avoid something. Every emotion (such as happiness or disgust) includes an affective reaction, but most of our affective reactions are too fleeting to be called emotions (location: 1033)


  - > More important, Zajonc was able to make people like any word or image more just by showing it to them several times.9 The brain tags familiar things as good things. (location: 1046)


  - > But if you do prejudge people implicitly (i.e., automatically and unconsciously), then those prejudgments include affective flashes, and those flashes will change your reaction times. (location: 1076)


  - > You can watch as your implicit attitude contradicts your explicit values. Most people turn out to have negative implicit associations with many social groups, such as black people, immigrants, obese people, and the elderly. (location: 1082)


  - > The words pro and life are both positive on their own, but part of what it means to be a partisan is that you have acquired the right set of intuitive reactions to hundreds of words and phrases. (location: 1090)


  - > People’s snap judgments of the candidates’ physical attractiveness and overall likability were not as good predictors of victory, so these competence judgments were not just based on an overall feeling of positivity. We can have multiple intuitions arising simultaneously, each one processing a different kind of information. (location: 1103)


  - > It helps guide the animal toward the right foods and away from the wrong ones. But in humans, this ancient food-processing center has taken on new duties, and it now guides our taste in people. It gets more active when we see something morally fishy, particularly something disgusting, as well as garden-variety unfairness.21 (location: 1115)


  - > Sure enough, people made harsher judgments when they were breathing in foul air.22 Other researchers have found the same effect by asking subjects to fill out questionnaires after drinking bitter versus sweet drinks.23 As my UVA colleague Jerry Clore puts it, we use “affect as information.”24 When we’re trying to decide what we think about something, we look inward, at how we’re feeling. If I’m feeling good, I must like it, and if I’m feeling anything unpleasant, that must mean I don’t like it. (location: 1127)


  - >  (location: 1135)
    This is wild... reminds me of drunk tank pink.

