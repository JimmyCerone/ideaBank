# Superintelligence: Paths, Dangers, Strategies

* Author: [[Nick Bostrom]]
* ASIN: [[B00LOOCGB2]]
* Reference: https://www.amazon.com/dp/B00LOOCGB2
* [Kindle link](kindle://book?action=open&asin=B00LOOCGB2)


  - > “We are all so small and weak. Imagine how easy life would be if we had an owl who could help us build our nests!” “Yes!” said another. “And we could use it to look after our elderly and our young.” “It could give us advice and keep an eye out for the neighborhood cat,” added a third. (location: 33)


  - > Only Scronkfinkle, a one-eyed sparrow with a fretful temperament, was unconvinced of the wisdom of the endeavor. Quoth he: “This will surely be our undoing. Should we not give some thought to the art of owl-domestication and owl-taming first, before we bring such a creature into our midst?” Replied Pastus: “Taming an owl sounds like an exceedingly difficult thing to do. It will be difficult enough to find an owl egg. So let us start there. After we have succeeded in raising an owl, then we can think about taking on this other challenge.” (location: 39)


  - >  (location: 58)
    This is profound...

  - > In practice, the control problem—the problem of how to control what the superintelligence would do—looks quite difficult. It also looks like we will only get one chance. (location: 59)


  - > This pattern has been taken to suggest that another (even faster) growth mode might be possible. However, we do not place much weight on this observation—this is not a book about “technological acceleration” or “exponential growth” or the miscellaneous notions sometimes gathered under the rubric of “the singularity.” (location: 298)
    Vaclov Smil

  - > Yet the prospect of continuing on a steady exponential growth path pales in comparison to what would happen if the world were to experience another step change in the rate of growth comparable in magnitude (location: 322)


  - > If another such transition to a different growth mode were to occur, and it were of similar magnitude to the previous two, it would result in a new growth regime in which the world economy would double in size about every two weeks. (location: 327)


  - > The singularity-related idea that interests us here is the possibility of an intelligence explosion, particularly the prospect of machine superintelligence. (location: 338)


  - > Machines matching humans in general intelligence—that is, possessing common sense and an effective ability to learn, reason, and plan to meet complex information-processing challenges across a wide range of natural and abstract domains—have been expected since the invention of computers in the 1940s. At that time, the advent of such machines was often placed some twenty years into the future.7 Since then, the expected arrival date has been receding at a rate of one year per year; so that today, futurists who concern themselves with the possibility of artificial general intelligence still often believe that intelligent machines are a couple of decades away.8 (location: 351)


  - > Twenty years may also be close to the typical duration remaining of a forecaster’s career, bounding the reputational risk of a bold prediction. (location: 361)
    Interesting note. Not sure I like their writing style so far.

  - > The main reason why progress has been slower than expected is that the technical difficulties of constructing intelligent machines have proved greater than the pioneers foresaw. (location: 364)


  - > But let us note at the outset that however many stops there are between here and human-level machine intelligence, the latter is not the final destination. The next stop, just a short distance farther along the tracks, is superhuman-level machine intelligence. (location: 368)
    This is a very salient point. I had never considered it.

  - > Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an “intelligence explosion,” and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.10 (location: 373)


  - > out….The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines that use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer. (location: 396)
    That's hilarious

  - > One such early system, the Logic Theorist, was able to prove most of the theorems in the second chapter of Whitehead and Russell’s Principia Mathematica, and even came up with one proof that was much more elegant than the original, thereby debunking the notion that machines could “only think numerically” and showing that machines were also able to do deduction and to invent logical proofs. (location: 407)


  - > make patentable inventions. (location: 420)
    What?

  - > The performance of these early systems also suffered because of poor methods for handling uncertainty, reliance on brittle and ungrounded symbolic representations, data scarcity, and severe hardware limitations on memory capacity and processor speed. (location: 434)


  - > While simple neural network models had been known since the late 1950s, the field enjoyed a renaissance after the introduction of the backpropagation algorithm, which made it possible to train multi-layered neural networks.24 (location: 466)


  - > Accordingly, one can view artificial intelligence as a quest to find shortcuts: ways of tractably approximating the Bayesian ideal by sacrificing some optimality or generality while preserving enough to get high performance in the actual domains of interest. (location: 503)


  - > “AI has by now succeeded in doing essentially everything that requires ‘thinking’ but has failed to do most of what people and animals do ‘without thinking’—that, somehow, is much harder!”60 (location: 633)
    System 1

  - > Common sense (location: 638)
    How do you defined this?

  - > Artificial intelligence methods are now used in more areas than it would make sense to review here, but mentioning a sampling of them will give an idea of the breadth of applications. (location: 652)
    It's interesting that we use humans as the standard of "greatness" even with all our biases and follies

  - > This approach dispenses with linguists: the programmers building these systems need not even speak the languages they are working with.67 (location: 667)
    Fascinating... They could be updated to keep up with slang as well

  - > Equation solvers are included in scientific computing programs such as Mathematica. (location: 673)
    I never considered that AI, what Wolfram does

  - > They also use automatic telephone reservation systems and helplines connected to speech recognition software to usher their hapless customers through labyrinths of interlocking menu options. (location: 681)
    How could we use AI in budgeting?

  - > though this brings us back to McCarthy’s dictum that when something works it is no longer called AI. (location: 689)


  - > Essentially all the systems currently in use are of the former type: narrow. However, many of them contain components that might also play a role in future artificial general intelligence or be of service in its development—components such as classifiers, search algorithms, planners, solvers, and representational frameworks. (location: 691)


  - > At 2:45 p.m., trading on the E-Mini was halted by an automatic circuit breaker, the exchange’s stop logic functionality. When trading was restarted, a mere five seconds later, prices stabilized and soon began to recover most of the losses. But for a while, at the trough of the crisis, a trillion dollars had been wiped off the market, and spillover effects had led to a substantial number of trades in individual securities being executed at “absurd” prices, such as one cent or 100,000 dollars. (location: 713)


  - > Systemic risk can build up in a system as new elements are introduced, risks that are not obvious until after something goes wrong (and sometimes not even then).71 (location: 724)
    This is a fascinating point and yet another reason to learn about systems / permaculture

  - > Another lesson is that smart professionals might give an instruction to a program based on a sensible-seeming and normally sound assumption (e.g. that trading volume is a good measure of market liquidity) and that this can produce catastrophic results when the program continues to act on the instruction with iron-clad logical consistency even in the unanticipated situation where the assumption turns out to be invalid. (location: 726)


  - > The need for pre-installed and automatically executing safety functionality—as opposed to reliance on runtime human supervision—again foreshadows a theme that will be important in our discussion of machine superintelligence.72 (location: 733)
    Ah that's a very salient point...

  - > The last few years have seen a resurgence of interest in AI, which might yet spill over into renewed efforts towards artificial general intelligence (what Nilsson calls “strong AI”). (location: 749)


  - > several relevant expert communities on the question of when they expect “human-level machine intelligence” (HLMI) (location: 760)
    How good does it have to be to get used? Like robocalls are in use and how effective are they compared to humans?

  - > Historically, AI researchers have not had a strong record of being able to predict the rate of advances in their own field or the shape that such advances would take. (location: 786)


  - > difficulties of getting a system to perform robustly on real-world tasks, and to overestimate the advantages of their own particular pet project or technique. (location: 789)
    Wicked learning environments. Interesting how much range has applied here thus far

  - > My own views again differ somewhat from the opinions expressed in the survey. I assign a higher probability to superintelligence being created relatively soon after human-level machine intelligence. I also have a more polarized outlook on the consequences, thinking an extremely good or an extremely bad outcome to be somewhat more likely than a more balanced outcome. (location: 804)


  - > We can tentatively define a superintelligence as any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest. (location: 821)
    But what if there are other domains? Or other types of intelligence for which we have no conception of?

  - > It is also noncommittal regarding qualia: whether a superintelligence would have subjective conscious experience might matter greatly for some questions (in particular for some moral questions), but our primary focus here is on the causal antecedents and consequences of superintelligence, not on the metaphysics of mind.2 (location: 826)


  - > For instance, an “engineering superintelligence” would be an intellect that vastly outperforms the best current human minds in the domain of engineering. Unless otherwise noted, we use the term to refer to systems that have a superhuman level of general intelligence. (location: 831)
    What would range say about this? Wouldn't this type of domain specific intelligence be limited in the same ways domain limited humans are?

  - > It now seems clear that a capacity to learn would be an integral feature of the core design of a system intended to attain general intelligence, not something to be tacked on later as an extension or an afterthought. The same holds for the ability to deal effectively with uncertainty and probabilistic information. (location: 839)
    So basically building something that can handle extremistan

  - > Instead of trying to produce a programme to simulate the adult mind, why not rather try to produce one which simulates the child’s? If this were then subjected to an appropriate course of education one would obtain the adult brain.3 (location: 847)
    Fascinating point...

  - > We cannot expect to find a good child machine at the first attempt. One must experiment with teaching one such machine and see how well it learns. One can then try another and see if it is better or worse. (location: 851)
    But what if the teaching method is incorrect? You're likely to get overfitting here

  - > The idea is that we can estimate the relative capabilities of evolution and human engineering to produce intelligence, and find that human engineering is already vastly superior to evolution in some areas and is likely to become superior in the remaining areas before too long. (location: 861)
    Are we really? What are the areas?

  - > before our culture mastered it.6 (location: 867)
    Did we master it though? It's super costly and inefficient, plus unsustainable

  - > But is it true that we will soon have computing power sufficient to recapitulate the relevant evolutionary processes that produced human intelligence? The (location: 878)
    also, what are we optimizing for will kindness be a factor?

  - > Only a small portion of evolutionary selection on Earth has been selection for intelligence. (location: 886)


  - > (By contrast, in pre-agricultural times there were fewer than 107 humans, with under 1011 neurons each: thus fewer than 1018 human neurons in total, though humans have a higher number of synapses per neuron.) (location: 908)
    What's the point of this calculation?

  - > Excessively deadly environments also reduce the value of intelligence: the shorter one’s expected lifespan, the less time there will be for increased learning ability to pay off. (location: 925)


  - > At one extreme—that of very close imitation—we have the idea of whole brain emulation, which we will discuss in the next subsection. (location: 940)
    Does it make sense to do this given the difference in structure between brains and computers? Is the brain binary?

  - > continuing incremental progress in brain science should eventually discover them all. (location: 949)
    Would this also uncover a soul or conscience?

  - > Yet the first functioning airplanes did not flap their wings. (location: 958)


  - > a seed AI would be a more sophisticated artificial intelligence capable of improving its own architecture. (location: 964)
    Now that is fascinating

  - > At its later stages, however, a seed AI should be able to understand its own workings sufficiently to engineer new algorithms and computational structures to bootstrap its cognitive performance. (location: 966)


  - > Before we end this subsection, there is one more thing that we should emphasize, which is that an artificial intelligence need not much resemble a human mind. (location: 979)
    Finally he says this my God

  - > AIs could be—indeed, it is likely that most will be—extremely alien. (location: 980)


  - > could eventually overcome any initial weakness). Furthermore, the goal systems of AIs could diverge radically from those of human beings. There is no reason to expect a generic AI to be motivated by love or hate or pride or other such common human sentiments: these complex adaptations would require deliberate expensive effort to recreate in AIs. (location: 982)


  - > The upshot is that the computational resources required to simply replicate the relevant evolutionary processes on Earth that produced human-level intelligence are severely out of reach—and will remain so even if Moore’s law were to continue for a century (cf. Figure 3). (location: 986)
    Wow. Ok now I understand what he was on about

  - > We must avoid the error of inferring, from the fact that intelligent life evolved on Earth, that the evolutionary processes involved had a reasonably high prior probability of producing intelligence. Such an inference is unsound because it fails to take account of the observation selection effect that guarantees that all observers will find themselves having originated on a planet where intelligent life arose, no matter how likely or unlikely it was for any given such planet to produce intelligence. (location: 1002)
    Taleb's remark about the rats

  - > In whole brain emulation (also known as “uploading”), intelligent software would be produced by scanning and closely modeling the computational structure of a biological brain. (location: 1018)


  - > This might involve stabilizing the brain post-mortem through vitrification (a process that turns tissue into a kind of glass). A machine could then dissect the tissue into thin slices, which could be fed into another machine for scanning, perhaps by an array of electron microscopes. (location: 1022)


  - > If completely successful, the result would be a digital reproduction of the original intellect, with memory and personality intact. The emulated human mind now exists as software on a computer. The mind can either inhabit a virtual reality or interface with the external world by means of robotic appendages. (location: 1038)
    This is so trippy.

  - > No fundamental conceptual or theoretical breakthrough is needed for whole brain emulation to succeed. (location: 1042)


  - > There are three key prerequisites: (1) scanning: high-throughput microscopy with sufficient resolution and detection of relevant properties; (location: 1044)


  - > (2) translation: automated image analysis to turn (location: 1045)


  - > comparison with these more challenging steps, the construction of a basic virtual reality or a robotic embodiment with an audiovisual input channel and some simple output channel is relatively easy. Simple yet minimally adequate I/O seems feasible already with present technology.23) (location: 1047)


  - > Just how much technology is required for whole brain emulation depends on the level of abstraction at which the brain is emulated. In this regard there is a tradeoff between insight and technology. (location: 1065)


