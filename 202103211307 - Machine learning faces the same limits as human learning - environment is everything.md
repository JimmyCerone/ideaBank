## Context
- Learned this while listening to [[202103181651 - The Quiet Master of Cryptocurrency]]. It makes intuitive sense when you think about it. 

## Idea
- This #Idea is based on a few #Assumptions most hold about the #Singularity (which is touched on in [[Superintelligence]]]):
	1. Materials are infinite
	2. Machines can learn "everything" if they are smart enough
	3. #Intelligence can be "general"

Naval blows this up quickly, which casts doubt on the likelihood of a #Singularity. Pulls on lots of [[Growth by Vaclov Smil]] principles, which I find fascinating. 

Here's his point by point refutation:
1. Obviously false. See Growth. Without unlimited materials, your machine is limited both by what it can be exposed to and what it can build / become. The assumption rests upon the idea that there are exponential amounts of material in the world. Superintelligence requires super materials (is this true?)
2. Learning is dependent on the #Environment. You can't learn what you don't see. So the challenge is that you can only teach a #Computer so much so fast. There are limits here and it's unclear if the current #Binary setup can transcend them (or perhaps, #Quantum)
3. Naval's claim that #Intelligence cannot be general blew my mind. #Human s are not even generally intelligent. There are so many fields we are uncapable of learning (smelling like a dog, for example). His point is that intelligence is more about adaptation to environment. - [[202103211316 - There is no such thing as general intelligence]]. 

So then we are left with a few [[03062021 - Levers]] that make the singularity hard:
1. Inputs
	- Environment
	- Building Materials
2. Processing
	- Method of processing (brain/organic, quantum, binary)